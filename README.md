# Empirical-Study-of-Adversarial-Attacks-on-ESC-
This code can be used to perform analysis of impact of adversarial attacks on environmental sound classification systems. A study is performed with seven state-of-the-art deep models well known to perform classification for computer vision related tasks. 
The empirical study includes analysis of fooling rate, transferability of adversarial examples and L2 peturbation distance as a measure to create the adversarial sample
by the deep model. This study is performed on three benchmark ESC datasets: ESC-10, Urban Sound 8K and DCASE 2019 Challenge Task-1(A) dataset.
